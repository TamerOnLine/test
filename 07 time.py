import logging
from langchain_ollama import OllamaLLM
from langchain.tools import Tool
from langchain.agents import initialize_agent, AgentType
from googlesearch import search
import warnings
import textwrap
import time

# Ø¥Ø¹Ø¯Ø§Ø¯ Ù†Ø¸Ø§Ù… ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)



# Ø¥Ø®ÙØ§Ø¡ ØªØ­Ø°ÙŠØ±Ø§Øª LangChain Ù…Ø¹ ØªØ³Ø¬ÙŠÙ„Ù‡Ø§ ÙÙŠ Ø§Ù„Ù€ logs
warnings.filterwarnings("ignore", category=DeprecationWarning)
logger.warning("âš ï¸ LangChainDeprecationWarning: It's recommended to migrate to LangGraph for new use cases.")


# Ù…Ø­Ø§ÙˆÙ„ ØªÙ‡ÙŠØ¦Ø© LLM Ù…Ø¹ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
try:
    llm = OllamaLLM(model="llama3", temperature=0)
    logger.info("âœ… LLM initialized successfully.")
except Exception as e:
    logger.error(f"âŒ Failed to initialize LLM: {e}", exc_info=True)
    llm = None  # ØªØ¬Ù†Ø¨ Ø§Ù†Ù‡ÙŠØ§Ø± Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„ÙØ´Ù„

def google_search(query: str, num_results: int = 2, use_llm: bool = True):
    """Search Google and summarize results using LLM (if enabled)."""
    logger.info(f"Received search query: {query}")

    try:
        results = list(search(query, stop=num_results))
        if not results:
            logger.warning("No results found for query.")
            return "âŒ No results found."

        # Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† LLM Ù…ÙØ¹Ù‘Ù„Ù‹Ø§ØŒ Ù†Ø±Ø¬Ø¹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙ‚Ø·
        if not use_llm or not llm:
            return f"ğŸ” Top search results:\n{results}"

        # ØªÙ…Ø±ÙŠØ± Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¥Ù„Ù‰ LLM ÙÙ‚Ø· Ø¥Ø°Ø§ ØªÙ… ØªÙ…ÙƒÙŠÙ†Ù‡
        summary_prompt = f"Summarize the key information about '{query}' based on these sources: {results}"
        summary = llm.invoke(summary_prompt)

        logger.debug(f"Search summary: {summary}")
        return summary

    except Exception as e:
        logger.error(f"Search failed due to: {e}", exc_info=True)
        return "âŒ An error occurred while searching."

def search_tool_handler(query):
    """Handles input for google_search tool, ensuring correct format."""
    use_llm = True  # Ø§ÙØªØ±Ø§Ø¶ÙŠÙ‹Ø§ ÙŠØªÙ… ØªÙØ¹ÙŠÙ„ LLM
    
    if isinstance(query, dict):
        # Ø§Ù„Ø³Ù…Ø§Ø­ Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¨ØªØ¹Ø·ÙŠÙ„ LLM Ø¥Ø°Ø§ Ø£Ø±Ø§Ø¯
        use_llm = query.get("use_llm", True)
        query_value = query.get("value", "")
    elif isinstance(query, str):
        query_value = query
    else:
        logger.warning("Invalid input format for search tool.")
        return "âŒ Invalid input format for search tool."

    return google_search(query_value, use_llm=use_llm)

# ØªØ­Ø¯ÙŠØ« ØªØ¹Ø±ÙŠÙ Ø§Ù„Ø£Ø¯Ø§Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
tools = [
    Tool(
        name="google_search",
        func=search_tool_handler,
        description="Search Google using a query and return summarized results."
    )
]

# Initialize agent ÙÙ‚Ø· Ø¥Ø°Ø§ ÙƒØ§Ù† LLM Ù…Ù‡ÙŠØ£ Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­
if llm:
    agent = initialize_agent(
        tools=tools,
        llm=llm,
        agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
        verbose=True,
        handle_parsing_errors=True,
        max_iterations=2,
        max_execution_time=None
    )
else:
    logger.error("âŒ Agent initialization failed due to LLM issue.")



def print_search_results(response):
    """Formats and prints search results in a clean way."""
    input_text = response.get("input", "Unknown Query")
    output_text = response.get("output", "No response available.")

    print("\nğŸ” Search Query:")
    print(f"   {input_text}")

    print("\nğŸ“Œ AI Response:")
    print(textwrap.fill(output_text, width=80))  # ØªØ­Ø¯ÙŠØ¯ Ø¹Ø±Ø¶ Ø§Ù„Ù†Øµ Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù‚Ø±Ø§Ø¡Ø©

    print("\n---------------------\n")




# Ù…ØªØºÙŠØ± Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„ÙˆÙ‚Øª Ø¨ÙŠÙ† ÙƒÙ„ Ø§Ø³ØªØ¹Ù„Ø§Ù…
last_search_time = 0
SEARCH_DELAY = 3  # ØªØ£Ø®ÙŠØ± 3 Ø«ÙˆØ§Ù†Ù Ø¨ÙŠÙ† ÙƒÙ„ Ø¨Ø­Ø« ÙˆØ¢Ø®Ø±

def enforce_rate_limit():
    """Ensures that searches are not too frequent."""
    global last_search_time
    elapsed_time = time.perf_counter() - last_search_time
    if elapsed_time < SEARCH_DELAY:
        wait_time = SEARCH_DELAY - elapsed_time
        print(f"â³ Waiting {wait_time:.1f} seconds before next search...")
        time.sleep(wait_time)
    last_search_time = time.perf_counter()

if __name__ == "__main__":
    print("\nğŸ” Welcome to the AI Search Agent! Type 'exit' to quit.\n")
    
    try:
        while True:
            query = input("\nğŸ” Enter your search query (or type 'exit' to exit): ").strip()
            if query.lower() == "exit":
                print("\nğŸ‘‹ Exiting the program. Have a great day!")
                break

            if not query:
                print("âš ï¸ Please enter a valid query.")
                continue

            enforce_rate_limit()  # ğŸ”¥ ØªÙØ¹ÙŠÙ„ Ù†Ø¸Ø§Ù… Ø§Ù„Ø­Ø¯ Ù…Ù† Ø¹Ø¯Ø¯ Ø§Ù„Ø·Ù„Ø¨Ø§Øª

            try:
                if llm:
                    response = agent.invoke({"input": query, "chat_history": []})
                    print_search_results(response)
                else:
                    print("âŒ LLM is not available. Please check your setup.")
            except Exception as e:
                logger.error(f"âŒ Error during execution: {e}", exc_info=True)
                print("âŒ An error occurred during execution.")
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ Exiting the program. See you next time!")
